{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, re, requests, os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.metromodels.com/en/main/'\n",
    "basedir = \"metromodels.com\"\n",
    "models_details=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get(url).content, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m models_dict \u001b[39m=\u001b[39m {link\u001b[39m.\u001b[39mimg[\u001b[39m'\u001b[39m\u001b[39malt\u001b[39m\u001b[39m'\u001b[39m]:link\u001b[39m.\u001b[39ma[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlistContainer\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfindAll(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodelElement\u001b[39m\u001b[39m'\u001b[39m)}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "models_dict = {link.img['alt']:link.a['href'] for link in soup.find('div', class_='listContainer').findAll('div', class_='modelElement')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse():\n",
    "    features = [feat.find('span').text.upper() for feat in soup1.find('ul', class_='bookModelMeasurements').findAll('li', class_='bookMeasurement')[:-1]]\n",
    "    values = [val.find('span', class_='mValue').text for val in soup1.find('ul', class_='bookModelMeasurements').findAll('li', class_='bookMeasurement') if val.find('span', class_='mValue')]\n",
    "    return dict(zip(features, values))\n",
    "\n",
    "def download_pics(pics):\n",
    "    patt = r\"\\w+-\\d+-[\\d+|\\w+]*.jpg\"\n",
    "    for pic in pics:\n",
    "        regex = re.search(patt,pic).group(0)\n",
    "        path = f\"{basedir}/{k}/{regex}\"\n",
    "        if not os.path.exists(path):\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(requests.get(pic).content)\n",
    "\n",
    "def list_to_csv(lst):\n",
    "    with open(f\"{basedir}/models_info.csv\",'w') as f:\n",
    "        c = csv.DictWriter(f, [\"NAME\",\"URL\", \"HEIGHT\", \"BUST / CHEST\",\"WAIST\",\"HIPS\" ,\"EYES\",\"HAIR\", \"SHOES\",\"CUP\"])\n",
    "        c.writeheader()\n",
    "        for row in lst:\n",
    "            c.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abby Neff https://www.metromodels.com/en/main/12-abby-neff/\n",
      "{'NAME': 'Abby Neff', 'URL': 'https://www.metromodels.com/en/main/12-abby-neff/', 'HEIGHT': '175', 'BUST / CHEST': '82', 'WAIST': '63', 'HIPS': '87', 'SHOES': '39', 'CUP': 'C', 'HAIR': 'Blond', 'EYES': 'Blue'}\n"
     ]
    }
   ],
   "source": [
    "for k,v in models_dict.items():\n",
    "    print(k,v)\n",
    "    os.makedirs(f\"{basedir}/{k}\", exist_ok=True)\n",
    "    soup1 = BeautifulSoup(requests.get(v).content, 'html5lib')\n",
    "    feat_dict = {'NAME':k, 'URL':v}\n",
    "    feat_dict.update(parse())\n",
    "    models_details.append(feat_dict)\n",
    "    pics=[pic.img['data-original'] for pic in soup1.findAll('div', class_='bookGalleryElement')]\n",
    "    download_pics(pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_csv(models_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
